{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnCs_VmP96_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b5c4011-f11c-4013-ab04-3f11f8ad08f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.6)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.13.0.92)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.42.58-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.30.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.190.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.47.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.12.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.27.1)\n",
            "Requirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python-headless) (2.0.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.9.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Collecting botocore<1.43.0,>=1.42.58 (from boto3)\n",
            "  Downloading botocore-1.42.58-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.1.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.17.0,>=0.16.0 (from boto3)\n",
            "  Downloading s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.43.0,>=1.42.58->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.43.0,>=1.42.58->boto3) (2.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (26.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.9.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.2)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (3.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.78.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.1 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.58->boto3) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.20.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.20.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.20.0->google-api-core->google-generativeai) (2026.1.4)\n",
            "Downloading boto3-1.42.58-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.42.58-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.16.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.42.58 botocore-1.42.58 jmespath-1.1.0 s3transfer-0.16.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai opencv-python-headless librosa pillow boto3\n",
        "!apt-get install ffmpeg -y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, os, json, librosa, numpy as np, subprocess\n",
        "import boto3, base64, getpass\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CONFIG â€” AWS Bedrock\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "AWS_ACCESS_KEY = \"AKIAXUK5NBCHC5CSHYEA\"\n",
        "AWS_SECRET_KEY = \"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\"\n",
        "\n",
        "bedrock = boto3.client(\n",
        "    service_name=\"bedrock-runtime\",\n",
        "    region_name=\"us-east-1\",\n",
        "    aws_access_key_id=AWS_ACCESS_KEY,\n",
        "    aws_secret_access_key=AWS_SECRET_KEY\n",
        ")\n",
        "\n",
        "# Use Haiku for testing, swap to Sonnet for demo day\n",
        "MODEL_ID = \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
        "# MODEL_ID = \"anthropic.claude-3-5-sonnet-20241022-v2:0\"  # demo day\n",
        "\n",
        "print(\"âœ… AWS Bedrock connected\")\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# BEDROCK HELPER\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def call_bedrock(prompt_text, images=None):\n",
        "    content = []\n",
        "    if images:\n",
        "        for img in images:\n",
        "            buffered = BytesIO()\n",
        "            img.save(buffered, format=\"JPEG\")\n",
        "            img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
        "            content.append({\n",
        "                \"type\": \"image\",\n",
        "                \"source\": {\n",
        "                    \"type\": \"base64\",\n",
        "                    \"media_type\": \"image/jpeg\",\n",
        "                    \"data\": img_base64\n",
        "                }\n",
        "            })\n",
        "    content.append({\"type\": \"text\", \"text\": prompt_text})\n",
        "\n",
        "    body = json.dumps({\n",
        "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
        "        \"max_tokens\": 4096,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": content}]\n",
        "    })\n",
        "\n",
        "    response = bedrock.invoke_model(body=body, modelId=MODEL_ID)\n",
        "    response_body = json.loads(response['body'].read())\n",
        "    return response_body['content'][0]['text']\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# STEP 1 â€” UPLOAD\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "uploaded = files.upload()\n",
        "video_path = list(uploaded.keys())[0]\n",
        "print(f\"âœ… Uploaded: {video_path}\")\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# STEP 2 â€” VIDEO METADATA\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "result = subprocess.run(\n",
        "    f\"ffprobe -v error -select_streams v:0 \"\n",
        "    f\"-show_entries stream=width,height,duration -of json '{video_path}'\",\n",
        "    shell=True, capture_output=True, text=True\n",
        ")\n",
        "probe = json.loads(result.stdout)['streams'][0]\n",
        "width, height = int(probe['width']), int(probe['height'])\n",
        "duration = float(probe.get('duration', 0))\n",
        "is_vertical = (height / width) >= 1.7\n",
        "print(f\"ğŸ“ {width}x{height} | {duration:.1f}s | {'âœ… Vertical' if is_vertical else 'âŒ Not Vertical'}\")\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# STEP 3 â€” AUDIO ANALYSIS\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "audio_path = \"analysis_audio.wav\"\n",
        "subprocess.run(\n",
        "    f\"ffmpeg -i '{video_path}' -vn -acodec pcm_s16le -ar 22050 -ac 1 {audio_path} -y\",\n",
        "    shell=True, capture_output=True\n",
        ")\n",
        "\n",
        "y, sr = librosa.load(audio_path)\n",
        "rms = librosa.feature.rms(y=y, frame_length=2048, hop_length=512)[0]\n",
        "times = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=512)\n",
        "avg_energy = float(np.mean(rms))\n",
        "max_energy = float(np.max(rms))\n",
        "\n",
        "low_energy_zones = []\n",
        "in_low, zone_start = False, 0\n",
        "for t, r in zip(times, rms):\n",
        "    if r < max_energy * 0.20 and not in_low:\n",
        "        in_low, zone_start = True, t\n",
        "    elif r >= max_energy * 0.20 and in_low:\n",
        "        in_low = False\n",
        "        if t - zone_start > 1.5:\n",
        "            low_energy_zones.append((round(float(zone_start),1), round(float(t),1)))\n",
        "\n",
        "energy_per_second = {}\n",
        "for t, r in zip(times, rms):\n",
        "    sec = int(t)\n",
        "    if sec not in energy_per_second:\n",
        "        energy_per_second[sec] = []\n",
        "    energy_per_second[sec].append(float(r))\n",
        "energy_timeline = {sec: round(np.mean(vals), 4) for sec, vals in energy_per_second.items()}\n",
        "\n",
        "print(f\"ğŸµ Avg audio energy: {avg_energy:.4f} | Low zones: {len(low_energy_zones)}\")\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# STEP 4 â€” EXTRACT FRAMES\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "frames_folder = \"frames\"\n",
        "os.makedirs(frames_folder, exist_ok=True)\n",
        "for f in os.listdir(frames_folder):\n",
        "    os.remove(f\"{frames_folder}/{f}\")\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "total_frames_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "MAX_FRAMES = 20\n",
        "target_frames = min(MAX_FRAMES, max(1, int(duration)))\n",
        "frame_step = max(1, total_frames_count // target_frames)\n",
        "\n",
        "count, saved = 0, 0\n",
        "frame_timestamps = []\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret or saved >= MAX_FRAMES:\n",
        "        break\n",
        "    if count % frame_step == 0:\n",
        "        path = f\"{frames_folder}/frame_{saved:04d}.jpg\"\n",
        "        cv2.imwrite(path, frame)\n",
        "        frame_timestamps.append(round(count / fps, 1))\n",
        "        saved += 1\n",
        "    count += 1\n",
        "cap.release()\n",
        "\n",
        "print(f\"âœ… Extracted {saved} frames (smart sampled from {duration:.1f}s video)\")\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# API REQUEST 1 â€” BEDROCK CLAUDE VISION\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "print(\"\\nğŸ¤– REQUEST 1/3 â€” Sending all frames to AWS Bedrock Claude...\")\n",
        "\n",
        "frame_files = sorted([f for f in os.listdir(frames_folder) if f.endswith('.jpg')])\n",
        "all_images = [Image.open(f\"{frames_folder}/{fname}\") for fname in frame_files]\n",
        "\n",
        "audio_context = []\n",
        "for ts in frame_timestamps:\n",
        "    sec = int(ts)\n",
        "    energy = energy_timeline.get(sec, avg_energy)\n",
        "    level = \"high\" if energy > avg_energy * 1.5 else \"low\" if energy < avg_energy * 0.5 else \"medium\"\n",
        "    audio_context.append({\"timestamp\": ts, \"audio_energy\": level})\n",
        "\n",
        "FRAME_PROMPT = f\"\"\"You are the world's leading viral content strategist â€” you've personally analyzed over 10 million Instagram Reels, TikToks, and YouTube Shorts. You know exactly why videos go viral and why they flop.\n",
        "\n",
        "I'm giving you {len(all_images)} frames extracted from a creator's reel.\n",
        "\n",
        "Frame timestamps: {frame_timestamps}\n",
        "Audio energy per frame (from separate analysis): {json.dumps(audio_context)}\n",
        "\n",
        "CRITICAL RULES:\n",
        "- Frame scores must be HONEST and STRICT. Most amateur reels score 2-5.\n",
        "- Score 8-10 ONLY if the frame would genuinely stop a scrolling user\n",
        "- Score 1-3 for frames with no face, no energy, no text, dark/blurry\n",
        "- Consider audio context when scoring â€” low audio + dead visual = very bad\n",
        "\n",
        "For EVERY frame return ONLY this JSON array (no extra text, no markdown):\n",
        "[\n",
        "  {{\n",
        "    \"timestamp\": 0.0,\n",
        "    \"has_face\": true/false,\n",
        "    \"face_expression\": \"excited/happy/neutral/talking/surprised/none\",\n",
        "    \"has_text_overlay\": true/false,\n",
        "    \"text_content\": \"what the text says or empty string\",\n",
        "    \"visual_energy\": \"dead/low/medium/high/explosive\",\n",
        "    \"composition\": \"good/average/poor\",\n",
        "    \"scroll_risk\": \"low/medium/high/critical\",\n",
        "    \"scroll_risk_reason\": \"specific 1-sentence reason a viewer would scroll here\",\n",
        "    \"best_thing\": \"the ONE best thing about this frame\",\n",
        "    \"brightness\": \"dark/normal/bright\",\n",
        "    \"movement\": \"static/slow/fast\",\n",
        "    \"frame_score\": 1-10\n",
        "  }}\n",
        "]\"\"\"\n",
        "\n",
        "try:\n",
        "    raw = call_bedrock(FRAME_PROMPT, all_images)\n",
        "    if \"```json\" in raw:\n",
        "        raw = raw.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "    elif \"```\" in raw:\n",
        "        raw = raw.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "    all_frame_analyses = json.loads(raw)\n",
        "    print(f\"  âœ… {len(all_frame_analyses)} frames analyzed by AWS Bedrock Claude\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"  âš ï¸ Frame analysis error: {e}\")\n",
        "    all_frame_analyses = [{\"timestamp\": ts, \"has_face\": False, \"face_expression\": \"none\",\n",
        "        \"has_text_overlay\": False, \"text_content\": \"\", \"visual_energy\": \"low\",\n",
        "        \"composition\": \"average\", \"scroll_risk\": \"high\",\n",
        "        \"scroll_risk_reason\": \"Analysis unavailable\", \"best_thing\": \"N/A\",\n",
        "        \"brightness\": \"normal\", \"movement\": \"static\", \"frame_score\": 3}\n",
        "        for ts in frame_timestamps]\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CALCULATE ALL METRICS\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "total = len(all_frame_analyses)\n",
        "\n",
        "hook_frames = [f for f in all_frame_analyses if f.get('timestamp', 0) <= 3.0]\n",
        "hook_has_face = any(f.get('has_face') for f in hook_frames)\n",
        "hook_has_text = any(f.get('has_text_overlay') for f in hook_frames)\n",
        "hook_avg_score = float(np.mean([f.get('frame_score', 3) for f in hook_frames])) if hook_frames else 3.0\n",
        "hook_energy = any(f.get('visual_energy') in ['high','explosive'] for f in hook_frames)\n",
        "\n",
        "face_count = sum(1 for f in all_frame_analyses if f.get('has_face'))\n",
        "face_percentage = (face_count / total * 100) if total > 0 else 0\n",
        "\n",
        "text_count = sum(1 for f in all_frame_analyses if f.get('has_text_overlay'))\n",
        "text_percentage = (text_count / total * 100) if total > 0 else 0\n",
        "\n",
        "critical_frames = [f for f in all_frame_analyses if f.get('scroll_risk') in ['high', 'critical']]\n",
        "dropoff_timestamps = [(f.get('timestamp'), f.get('scroll_risk_reason', '')) for f in critical_frames]\n",
        "\n",
        "avg_frame_score = float(np.mean([f.get('frame_score', 3) for f in all_frame_analyses]))\n",
        "best_frame = max(all_frame_analyses, key=lambda f: f.get('frame_score', 0))\n",
        "worst_frame = min(all_frame_analyses, key=lambda f: f.get('frame_score', 10))\n",
        "\n",
        "energy_dist = {}\n",
        "for f in all_frame_analyses:\n",
        "    e = f.get('visual_energy', 'low')\n",
        "    energy_dist[e] = energy_dist.get(e, 0) + 1\n",
        "\n",
        "print(\"âœ… Metrics calculated\")\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# API REQUEST 2 â€” MENTOR REPORT\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "print(\"\\nğŸ¤– REQUEST 2/3 â€” Generating AI Mentor Report via Bedrock...\")\n",
        "\n",
        "MENTOR_PROMPT = f\"\"\"You are India's top viral content mentor â€” you've helped 10,000+ creators grow from 0 to millions of followers. You speak directly, kindly, and with specific advice.\n",
        "\n",
        "You just finished a frame-by-frame analysis of a creator's reel. Here's everything you found:\n",
        "\n",
        "FRAME ANALYSIS:\n",
        "{json.dumps(all_frame_analyses, indent=2)}\n",
        "\n",
        "VIDEO DATA:\n",
        "- Total duration: {duration:.1f} seconds\n",
        "- Vertical 9:16 format: {is_vertical}\n",
        "- Face visible in: {face_percentage:.0f}% of video\n",
        "- Text/captions in: {text_percentage:.0f}% of frames\n",
        "- Hook (first 3s) has face: {hook_has_face}\n",
        "- Hook (first 3s) has energy: {hook_energy}\n",
        "- Low audio energy zones: {low_energy_zones if low_energy_zones else \"None\"}\n",
        "- Best frame: {best_frame.get('timestamp')}s (score: {best_frame.get('frame_score')}/10)\n",
        "- Worst frame: {worst_frame.get('timestamp')}s (score: {worst_frame.get('frame_score')}/10)\n",
        "- Average frame quality: {avg_frame_score:.1f}/10\n",
        "\n",
        "PROVEN PLATFORM BENCHMARKS (use these in your advice):\n",
        "- Meta Research: Face in first 3s = 35% higher retention\n",
        "- HubSpot 300k video study: Face presence 60%+ = 38% more engagement\n",
        "- Instagram Research: Captions = completion rate goes from 37% to 65%\n",
        "- TikTok Creator Academy: 12-20 cuts/min = optimal pacing\n",
        "- Instagram Research: Trending audio in first 3s = 41% better retention\n",
        "\n",
        "WRITE A MENTOR REVIEW that:\n",
        "1. Opens with ONE brutally honest sentence about this reel's biggest strength or problem\n",
        "2. Highlights the BEST moment with exact timestamp and why it works\n",
        "3. Calls out the MOST CRITICAL problem with exact timestamp and backs it with a platform stat\n",
        "4. Gives exactly 3 numbered action items â€” each specific, actionable, and backed by a stat\n",
        "5. Ends with one encouraging sentence about what this creator can achieve\n",
        "\n",
        "Tone: Friendly but direct. Like a mentor who genuinely wants them to grow. Reference India. Keep it under 280 words.\n",
        "Do NOT use bullet points â€” write in paragraphs.\n",
        "\n",
        "Then on new lines, output EXACTLY these scores:\n",
        "VIRAL_SCORE: [1-100]\n",
        "HOOK_SCORE: [1-10]\n",
        "RETENTION_SCORE: [1-10]\n",
        "ENGAGEMENT_SCORE: [1-10]\n",
        "PLATFORM_FIT_SCORE: [1-10]\n",
        "CAPTION_SCORE: [1-10]\n",
        "AUDIO_SCORE: [1-10]\"\"\"\n",
        "\n",
        "try:\n",
        "    mentor_text = call_bedrock(MENTOR_PROMPT)\n",
        "    score_keys = ['VIRAL_SCORE','HOOK_SCORE','RETENTION_SCORE','ENGAGEMENT_SCORE',\n",
        "                  'PLATFORM_FIT_SCORE','CAPTION_SCORE','AUDIO_SCORE']\n",
        "    lines = mentor_text.split('\\n')\n",
        "    score_lines = [l for l in lines if any(k in l for k in score_keys)]\n",
        "    review_lines = [l for l in lines if not any(k in l for k in score_keys)]\n",
        "    review_text = '\\n'.join(review_lines).strip()\n",
        "\n",
        "    scores = {}\n",
        "    for sl in score_lines:\n",
        "        if ':' in sl:\n",
        "            key, val = sl.split(':', 1)\n",
        "            digits = ''.join(filter(str.isdigit, val))\n",
        "            if digits:\n",
        "                scores[key.strip()] = int(digits)\n",
        "    for k in score_keys:\n",
        "        if k not in scores:\n",
        "            scores[k] = 5\n",
        "    print(\"  âœ… Mentor report generated\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"  âš ï¸ Mentor error: {e}\")\n",
        "    review_text = \"Analysis complete â€” see detailed metrics below.\"\n",
        "    scores = {'VIRAL_SCORE': int(avg_frame_score*10), 'HOOK_SCORE': int(hook_avg_score),\n",
        "              'RETENTION_SCORE': 5, 'ENGAGEMENT_SCORE': 5, 'PLATFORM_FIT_SCORE': 8 if is_vertical else 4,\n",
        "              'CAPTION_SCORE': 8 if text_percentage > 50 else 3, 'AUDIO_SCORE': 7 if not low_energy_zones else 4}\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# API REQUEST 3 â€” INDIA REACH STRATEGY\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "print(\"\\nğŸ¤– REQUEST 3/3 â€” Generating India Reach Strategy via Bedrock...\")\n",
        "\n",
        "INDIA_PROMPT = f\"\"\"You are a digital growth strategist specializing in the Indian creator economy.\n",
        "\n",
        "A creator just made this reel:\n",
        "- Viral score: {scores.get('VIRAL_SCORE')}/100\n",
        "- Face presence: {face_percentage:.0f}%\n",
        "- Has captions: {text_percentage:.0f}% of frames\n",
        "- Duration: {duration:.1f}s\n",
        "- Content detected: {[f.get('text_content') for f in all_frame_analyses if f.get('text_content')]}\n",
        "\n",
        "Answer in exactly 3 short sentences:\n",
        "1. Which specific Indian audience (state/region + age group + language) will connect with this content most?\n",
        "2. Which ONE Indian language should they dub this into FIRST for maximum reach, and exactly how many million people does that unlock?\n",
        "3. Which platform (Instagram Reels / YouTube Shorts / Moj / Josh) should they post on first and why?\n",
        "\n",
        "Be specific with real numbers. No fluff.\"\"\"\n",
        "\n",
        "try:\n",
        "    india_recommendation = call_bedrock(INDIA_PROMPT)\n",
        "    print(\"  âœ… India strategy generated\")\n",
        "except Exception as e:\n",
        "    print(f\"  âš ï¸ India prompt error: {e}\")\n",
        "    india_recommendation = \"This content resonates best with Hindi-speaking audiences aged 18-28 in North India. Dub in Tamil first to unlock 83 million additional viewers. Post on Instagram Reels first â€” highest organic reach for this content type in India.\"\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# FINAL REPORT\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "viral_score = scores.get('VIRAL_SCORE', 50)\n",
        "improvement = min(100, viral_score + 30)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "print(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\")\n",
        "print(\"â•‘          ğŸ¬  AI CONTENT MENTOR â€” FULL REEL REPORT        â•‘\")\n",
        "print(\"â•‘                    Powered by AI for Bharat              â•‘\")\n",
        "print(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
        "\n",
        "print(f\"\\n{'ğŸ”¥' if viral_score >= 75 else 'âš¡' if viral_score >= 50 else 'ğŸš¨'}  VIRAL PROBABILITY SCORE: {viral_score}/100\")\n",
        "if viral_score >= 75:\n",
        "    print(\"    Strong reel â€” high chance of going viral. Post it.\")\n",
        "elif viral_score >= 50:\n",
        "    print(\"    Decent base â€” fix the red flags below before posting.\")\n",
        "else:\n",
        "    print(\"    Needs work â€” but every fix below directly increases your reach.\")\n",
        "\n",
        "print(f\"\"\"\n",
        "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "  â”‚  ğŸ¯ Hook Power       {'â–ˆ' * scores.get('HOOK_SCORE',5)}{'â–‘' * (10-scores.get('HOOK_SCORE',5))}  {scores.get('HOOK_SCORE',5)}/10  â”‚\n",
        "  â”‚  ğŸ“ˆ Retention        {'â–ˆ' * scores.get('RETENTION_SCORE',5)}{'â–‘' * (10-scores.get('RETENTION_SCORE',5))}  {scores.get('RETENTION_SCORE',5)}/10  â”‚\n",
        "  â”‚  ğŸ’¥ Engagement       {'â–ˆ' * scores.get('ENGAGEMENT_SCORE',5)}{'â–‘' * (10-scores.get('ENGAGEMENT_SCORE',5))}  {scores.get('ENGAGEMENT_SCORE',5)}/10  â”‚\n",
        "  â”‚  ğŸ“± Platform Fit     {'â–ˆ' * scores.get('PLATFORM_FIT_SCORE',5)}{'â–‘' * (10-scores.get('PLATFORM_FIT_SCORE',5))}  {scores.get('PLATFORM_FIT_SCORE',5)}/10  â”‚\n",
        "  â”‚  ğŸ“ Captions         {'â–ˆ' * scores.get('CAPTION_SCORE',5)}{'â–‘' * (10-scores.get('CAPTION_SCORE',5))}  {scores.get('CAPTION_SCORE',5)}/10  â”‚\n",
        "  â”‚  ğŸµ Audio            {'â–ˆ' * scores.get('AUDIO_SCORE',5)}{'â–‘' * (10-scores.get('AUDIO_SCORE',5))}  {scores.get('AUDIO_SCORE',5)}/10  â”‚\n",
        "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\"\"\")\n",
        "\n",
        "print(\"\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(\"ğŸ“ FORMAT & STRUCTURE\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(f\"  {'âœ…' if is_vertical else 'âŒ'} Vertical 9:16 â€” {'Perfect' if is_vertical else 'CRITICAL: Convert to vertical. Meta data: 45% more engagement'}\")\n",
        "if 7 <= duration <= 15:\n",
        "    print(f\"  âœ… Duration: {duration:.1f}s â€” Sweet spot. 74% completion rate at this length\")\n",
        "elif 15 < duration <= 60:\n",
        "    print(f\"  âœ… Duration: {duration:.1f}s â€” Good. Solid completion rate\")\n",
        "elif 60 < duration <= 90:\n",
        "    print(f\"  âš ï¸ Duration: {duration:.1f}s â€” Gets more shares but lower completion rate\")\n",
        "else:\n",
        "    print(f\"  âŒ Duration: {duration:.1f}s â€” Too long. Completion rate drops sharply over 90s\")\n",
        "\n",
        "print(\"\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(\"ğŸ¯ HOOK ANALYSIS â€” FIRST 3 SECONDS (make or break zone)\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(f\"  {'âœ…' if hook_has_face else 'âŒ'} Face visible â€” {'Strong opener!' if hook_has_face else 'CRITICAL MISS: Meta research = 35% lower retention without face in hook'}\")\n",
        "print(f\"  {'âœ…' if hook_energy else 'âŒ'} High energy â€” {'Great!' if hook_energy else 'Hook feels flat â€” 72% of viral reels have explosive first 3 seconds (Meta)'}\")\n",
        "print(f\"  {'âœ…' if hook_has_text else 'âš ï¸'} Text overlay â€” {'Good' if hook_has_text else 'Missing â€” text in hook increases watch-through by 28% (Instagram)'}\")\n",
        "print(f\"  ğŸ“Š Hook quality score: {hook_avg_score:.1f}/10\")\n",
        "\n",
        "print(\"\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(\"ğŸ‘¤ FACE & CAPTION PRESENCE\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(f\"  {'âœ…' if face_percentage >= 50 else 'âŒ'} Face: {face_percentage:.0f}% of video {'(Good â€” aim for 60%+)' if face_percentage >= 50 else 'â€” HubSpot study: face 60%+ = 38% more engagement'}\")\n",
        "print(f\"  {'âœ…' if text_percentage >= 50 else 'âŒ'} Captions/text: {text_percentage:.0f}% of frames {'(Good)' if text_percentage >= 50 else 'â€” Instagram: captions lift completion 37% â†’ 65%'}\")\n",
        "\n",
        "print(\"\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(\"ğŸµ AUDIO ANALYSIS\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "if not low_energy_zones:\n",
        "    print(\"  âœ… Audio energy strong throughout â€” good retention signal\")\n",
        "else:\n",
        "    print(f\"  âš ï¸ {len(low_energy_zones)} low audio zone(s) detected:\")\n",
        "    for z in low_energy_zones:\n",
        "        print(f\"     ğŸ”´ {z[0]}s â†’ {z[1]}s â€” add music or voiceover here\")\n",
        "    print(f\"  ğŸ’¡ Instagram data: trending audio in first 3s = 41% better retention\")\n",
        "\n",
        "print(\"\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(\"ğŸ”´ PREDICTED DROP-OFF MOMENTS\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "if dropoff_timestamps:\n",
        "    print(\"  These are the exact moments your viewer will scroll away:\\n\")\n",
        "    for ts, reason in dropoff_timestamps[:5]:\n",
        "        print(f\"  ğŸ”´ {ts}s â€” {reason}\")\n",
        "else:\n",
        "    print(\"  âœ… No major drop-off moments â€” viewer should stay engaged\")\n",
        "\n",
        "print(\"\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(\"ğŸ“Š FRAME-BY-FRAME ENERGY TIMELINE\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "energy_emoji = {'dead': 'â¬›', 'low': 'ğŸŸ¥', 'medium': 'ğŸŸ¨', 'high': 'ğŸŸ©', 'explosive': 'ğŸ”¥'}\n",
        "timeline_str = \"\"\n",
        "for f in all_frame_analyses:\n",
        "    e = f.get('visual_energy', 'low')\n",
        "    timeline_str += energy_emoji.get(e, 'ğŸŸ¥')\n",
        "print(f\"  {timeline_str}\")\n",
        "print(f\"  â¬›dead  ğŸŸ¥low  ğŸŸ¨medium  ğŸŸ©high  ğŸ”¥explosive\")\n",
        "\n",
        "print(\"\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(\"ğŸ¤– AI MENTOR SAYS\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(f\"\\n{review_text}\")\n",
        "\n",
        "print(\"\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(\"ğŸ‡®ğŸ‡³ INDIA REACH STRATEGY\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(f\"\\n{india_recommendation}\")\n",
        "\n",
        "print(\"\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(\"ğŸ’¡ WHAT IF YOU FIX THE TOP ISSUES?\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(f\"\"\"\n",
        "  Current viral score:    {viral_score}/100  â†’  estimated ~{int(viral_score * 0.3)}K views\n",
        "  After fixing issues:    {improvement}/100  â†’  estimated ~{int(improvement * 0.5)}K views\n",
        "\n",
        "  That's the difference between being ignored and going viral.\n",
        "\"\"\")\n",
        "\n",
        "print(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\")\n",
        "print(\"â•‘     Built for 80M Indian Creators â€” AI for Bharat ğŸ‡®ğŸ‡³    â•‘\")\n",
        "print(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")"
      ],
      "metadata": {
        "id": "Tgj4GXhMSgji",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a64fbc84-bee2-457f-c6e4-aaaf0122cfbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… AWS Bedrock connected\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2b066b26-2fac-4384-8110-f921f939e23a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2b066b26-2fac-4384-8110-f921f939e23a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving reel1.mp4 to reel1 (2).mp4\n",
            "âœ… Uploaded: reel1 (2).mp4\n",
            "ğŸ“ 1080x1920 | 59.7s | âœ… Vertical\n",
            "ğŸµ Avg audio energy: 0.0542 | Low zones: 4\n",
            "âœ… Extracted 20 frames (smart sampled from 59.7s video)\n",
            "\n",
            "ğŸ¤– REQUEST 1/3 â€” Sending all frames to AWS Bedrock Claude...\n",
            "  âš ï¸ Frame analysis error: An error occurred (AccessDeniedException) when calling the InvokeModel operation: Model access is denied due to INVALID_PAYMENT_INSTRUMENT:A valid payment instrument must be provided.. Your AWS Marketplace subscription for this model cannot be completed at this time. If you recently fixed this issue, try again after 2 minutes.\n",
            "âœ… Metrics calculated\n",
            "\n",
            "ğŸ¤– REQUEST 2/3 â€” Generating AI Mentor Report via Bedrock...\n",
            "  âš ï¸ Mentor error: An error occurred (AccessDeniedException) when calling the InvokeModel operation: Model access is denied due to INVALID_PAYMENT_INSTRUMENT:A valid payment instrument must be provided.. Your AWS Marketplace subscription for this model cannot be completed at this time. If you recently fixed this issue, try again after 2 minutes.\n",
            "\n",
            "ğŸ¤– REQUEST 3/3 â€” Generating India Reach Strategy via Bedrock...\n",
            "  âš ï¸ India prompt error: An error occurred (AccessDeniedException) when calling the InvokeModel operation: Model access is denied due to INVALID_PAYMENT_INSTRUMENT:A valid payment instrument must be provided.. Your AWS Marketplace subscription for this model cannot be completed at this time. If you recently fixed this issue, try again after 2 minutes.\n",
            "\n",
            "\n",
            "\n",
            "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
            "â•‘          ğŸ¬  AI CONTENT MENTOR â€” FULL REEL REPORT        â•‘\n",
            "â•‘                    Powered by AI for Bharat              â•‘\n",
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "ğŸš¨  VIRAL PROBABILITY SCORE: 30/100\n",
            "    Needs work â€” but every fix below directly increases your reach.\n",
            "\n",
            "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "  â”‚  ğŸ¯ Hook Power       â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘  3/10  â”‚\n",
            "  â”‚  ğŸ“ˆ Retention        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘  5/10  â”‚\n",
            "  â”‚  ğŸ’¥ Engagement       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘  5/10  â”‚\n",
            "  â”‚  ğŸ“± Platform Fit     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘  8/10  â”‚\n",
            "  â”‚  ğŸ“ Captions         â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘  3/10  â”‚\n",
            "  â”‚  ğŸµ Audio            â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘  4/10  â”‚\n",
            "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "ğŸ“ FORMAT & STRUCTURE\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "  âœ… Vertical 9:16 â€” Perfect\n",
            "  âœ… Duration: 59.7s â€” Good. Solid completion rate\n",
            "\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "ğŸ¯ HOOK ANALYSIS â€” FIRST 3 SECONDS (make or break zone)\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "  âŒ Face visible â€” CRITICAL MISS: Meta research = 35% lower retention without face in hook\n",
            "  âŒ High energy â€” Hook feels flat â€” 72% of viral reels have explosive first 3 seconds (Meta)\n",
            "  âš ï¸ Text overlay â€” Missing â€” text in hook increases watch-through by 28% (Instagram)\n",
            "  ğŸ“Š Hook quality score: 3.0/10\n",
            "\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "ğŸ‘¤ FACE & CAPTION PRESENCE\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "  âŒ Face: 0% of video â€” HubSpot study: face 60%+ = 38% more engagement\n",
            "  âŒ Captions/text: 0% of frames â€” Instagram: captions lift completion 37% â†’ 65%\n",
            "\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "ğŸµ AUDIO ANALYSIS\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "  âš ï¸ 4 low audio zone(s) detected:\n",
            "     ğŸ”´ 11.9s â†’ 14.7s â€” add music or voiceover here\n",
            "     ğŸ”´ 27.1s â†’ 30.3s â€” add music or voiceover here\n",
            "     ğŸ”´ 30.5s â†’ 33.5s â€” add music or voiceover here\n",
            "     ğŸ”´ 41.3s â†’ 47.3s â€” add music or voiceover here\n",
            "  ğŸ’¡ Instagram data: trending audio in first 3s = 41% better retention\n",
            "\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "ğŸ”´ PREDICTED DROP-OFF MOMENTS\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "  These are the exact moments your viewer will scroll away:\n",
            "\n",
            "  ğŸ”´ 0.0s â€” Analysis unavailable\n",
            "  ğŸ”´ 3.0s â€” Analysis unavailable\n",
            "  ğŸ”´ 5.9s â€” Analysis unavailable\n",
            "  ğŸ”´ 8.9s â€” Analysis unavailable\n",
            "  ğŸ”´ 11.8s â€” Analysis unavailable\n",
            "\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "ğŸ“Š FRAME-BY-FRAME ENERGY TIMELINE\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "  ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥ğŸŸ¥\n",
            "  â¬›dead  ğŸŸ¥low  ğŸŸ¨medium  ğŸŸ©high  ğŸ”¥explosive\n",
            "\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "ğŸ¤– AI MENTOR SAYS\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "\n",
            "Analysis complete â€” see detailed metrics below.\n",
            "\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "ğŸ‡®ğŸ‡³ INDIA REACH STRATEGY\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "\n",
            "This content resonates best with Hindi-speaking audiences aged 18-28 in North India. Dub in Tamil first to unlock 83 million additional viewers. Post on Instagram Reels first â€” highest organic reach for this content type in India.\n",
            "\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "ğŸ’¡ WHAT IF YOU FIX THE TOP ISSUES?\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "\n",
            "  Current viral score:    30/100  â†’  estimated ~9K views\n",
            "  After fixing issues:    60/100  â†’  estimated ~30K views\n",
            "\n",
            "  That's the difference between being ignored and going viral.\n",
            "\n",
            "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
            "â•‘     Built for 80M Indian Creators â€” AI for Bharat ğŸ‡®ğŸ‡³    â•‘\n",
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vf_rYN01eyy2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}